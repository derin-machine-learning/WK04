{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Week 04\n",
    "\n",
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this week's exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2026S-A/5020-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from image_utils import blur, edges, get_pixels, make_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as lists (of lists) of pixels\n",
    "\n",
    "Just a quick review of how images are usually represented and stored in files and memory.\n",
    "\n",
    "An image:<br>\n",
    "<img src=\"./imgs/pixel-00.jpg\" height=\"250px\">\n",
    "\n",
    "is a collection of rows:<br>\n",
    "<img src=\"./imgs/pixel-01.jpg\" height=\"250px\">\n",
    "\n",
    "which are collections of pixels:<br>\n",
    "<img src=\"./imgs/pixel-03.jpg\" height=\"250px\">\n",
    "\n",
    "which are lists of color values:<br>\n",
    "<img src=\"./imgs/pixel-04.jpg\" height=\"250px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading image files\n",
    "\n",
    "We can use the `Image` object from the [PIL](https://pillow.readthedocs.io/en/stable/) library to open image files.\n",
    "\n",
    "It's as simple as doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L66UbgCWGDjF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "mimg = PImage.open(\"./data/hog.jpg\")\n",
    "display(mimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `mimg` is an image object and we can get some information about our image directly from this object.\n",
    "\n",
    "### Image properties\n",
    "\n",
    "<img src=\"./imgs/image-00.jpg\" width=\"720px\">\n",
    "\n",
    "For example, to get its dimensions, in pixels, we can access its `size` variable, which holds $2$ values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mimg.size)\n",
    "print(mimg.size[0], mimg.size[1])\n",
    "\n",
    "iw, ih = mimg.size\n",
    "print(iw, ih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = mimg.size\n",
    "\n",
    "print(image_width, \"x\", image_height)\n",
    "print(\"total number of pixels:\", image_width * image_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to get the number of channels we can call its `getbands()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimg.getbands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0, b1, b2 = mimg.getbands()\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands0, bands1 = mimg.getbands()\n",
    "# ERROR !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_count = len(mimg.getbands())\n",
    "\n",
    "print(channel_count, \"channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About channels\n",
    "\n",
    "Grayscale images have $1$ channel: each pixel holds a value between $0$ and $255$ that represents how bright that pixels is.\n",
    "\n",
    "RGB images have $3$ channels: each pixel is represented by $3$ values, one for each of the colors red, green and blue.\n",
    "\n",
    "RGBA images have $4$ channels: each pixel has $3$ values for its RGB components, plus an extra one for transparency.\n",
    "\n",
    "<img src=\"./imgs/image-01.jpg\" width=\"720px\">\n",
    "\n",
    "This is important because when we get the list of pixels for an image we need to know what to expect from each of the list's members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the image\n",
    "\n",
    "We can just call the built-in notebook function `display()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info for another image\n",
    "\n",
    "Either upload a different image to the notebook, or open up the `data/flowers.jpg` image and print out its width, height, total number of pixels and number of channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an image of my local bookstore's cat in Istanbul\n",
    "\n",
    "oimg = PImage.open(\"./data/bookstore-cat.jpg\")\n",
    "print(oimg)\n",
    "print(oimg.size, oimg.getbands())\n",
    "display(oimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting pixel color lists\n",
    "\n",
    "We can also easily get a list of all the pixel color values by calling the object's `getdata()` member function and turning the result into a `list`.\n",
    "\n",
    "This list has $width \\times height$ elements, one for each pixel on the image, and when working with RGB images, each pixel element will have $3$ values.\n",
    "\n",
    "We can take a look at some pixel values, and check that the length of the pixel array is equal to the $width$ of the image times its $height$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixels = list(mimg.getdata())\n",
    "print(len(img_pixels))\n",
    "img_pixels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixels = list(mimg.getdata())\n",
    "\n",
    "print(mimg.size, mimg.size[0] * mimg.size[1], len(img_pixels))\n",
    "print(img_pixels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixels = get_pixels(mimg)\n",
    "len(img_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we view our images as two-dimensional arrangements of colors, in memory and in files, they're just long lists of numbers.\n",
    "\n",
    "<img src=\"./imgs/image-02.jpg\" width=\"720px\">\n",
    "\n",
    "And, just like with audio files, we can create or manipulate these numeric lists before viewing them as images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating images from pixel color lists\n",
    "\n",
    "This is a bit trickier.\n",
    "\n",
    "We first have to create an empty image with a given size and specific number of channels, and then pass a list of pixel values to fill it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates an empty grayscale image with size 400 x 400\n",
    "rimg = PImage.new(\"L\", (400, 400))\n",
    "\n",
    "# This fills a list with 400 * 400 random values between 0 and 255\n",
    "rpix_vals = []\n",
    "for i in range(400 * 400):\n",
    "  rpix_vals.append(int(i/160000 * 255))\n",
    "\n",
    "# This puts the pixel values into the image object, so we can visualize it\n",
    "rimg.putdata(rpix_vals)\n",
    "display(rimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An RGB example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates an empty, 3-channel, RGB image with size 400 x 400\n",
    "rimg = PImage.new(\"RGB\", (400, 400))\n",
    "\n",
    "# This fills a list with 400 * 400 RGB values\n",
    "rpix_vals = []\n",
    "for i in range(400 * 400):\n",
    "  r = int(i / 160000 * 255)\n",
    "  b = 255 - int(i / 160000 * 255)\n",
    "  rpix_vals.append((r, 0, b))\n",
    "\n",
    "# This puts the pixel values into the image object, so we can visualize it\n",
    "rimg.putdata(rpix_vals)\n",
    "display(rimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ˜µâ€ðŸ’«ðŸ˜–\n",
    "\n",
    "And, just like with audio files and sample lists, it's kind of annoying to always be turning pixels into images and images into pixels like this.\n",
    "\n",
    "Additionally, if the content of the pixel list passed to the function doesn't match the expected number of pixels or channels, the conversion will fail.\n",
    "\n",
    "Luckily, we can use some helper functions to make this easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images and Pixels\n",
    "\n",
    "We can use the helper functions `get_pixels()` and `make_image()` to convert between pixel arrays and PIL images.\n",
    "\n",
    "If the `make_image()` function is called with just an array of pixels it will assume we want a square image with equal width and height. To make an image with a more specific size, at least one more parameter has to be used: `make_image(pixels, width, height)`.\n",
    "\n",
    "or even just: `make_image(pixels, width)` and it will figure out the height automatically.\n",
    "\n",
    "Something like the example above could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fills a list with 400 * 400 RGB values\n",
    "rpix_vals = [(int(i / 160000 * 255), 0, 255 - int(i / 160000 * 255)) for i in range(400*400)]\n",
    "\n",
    "# This creates an image object from the pixel values so we can visualize it\n",
    "\n",
    "# if we don't give it a width, it assumes a square image\n",
    "rimg = make_image(rpix_vals)\n",
    "display(rimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we give it a width, it will calculate the height given the number of elements on the list\n",
    "rimg = make_image(rpix_vals, 800)\n",
    "display(rimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating images\n",
    "\n",
    "Since the pixel array is a separate object from the `PImage` object, once we change an image's pixel array we have to create a new image to see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "himg_copy_pxs = get_pixels(himg)\n",
    "mid_idx = len(himg_copy_pxs) // 2\n",
    "\n",
    "for idx in range(0, mid_idx):\n",
    "  himg_copy_pxs[idx] = himg_copy_pxs[mid_idx + idx]\n",
    "\n",
    "display(himg)\n",
    "\n",
    "himg_new_copy = make_image(himg_copy_pxs, himg.size[0])\n",
    "display(himg_new_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn into Grayscale\n",
    "\n",
    "We start with an empty list to hold our new pixels. We then go through all pixels in the image and append their average `R`,`G`,`B` value to the new image as a grayscale, single-value, pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "himg_pxs = get_pixels(himg)\n",
    "\n",
    "gray_pxs = []\n",
    "for r,g,b in himg_pxs:\n",
    "  l = (r + g + b) / 3\n",
    "  gray_pxs.append(l)\n",
    "\n",
    "nimg = make_image(gray_pxs, himg.width)\n",
    "nimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing pixels\n",
    "\n",
    "### Visualizing color channel\n",
    "\n",
    "We can create new images by changing the values of the pixels in our list.\n",
    "\n",
    "For example, if we want to separate the `red` component of our image, we can go through all of the pixel values and remove their `green` and `blue` components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "himg_pxs = get_pixels(himg)\n",
    "\n",
    "# build array of new pixel values\n",
    "redpxs = []\n",
    "for r,g,b in himg_pxs:\n",
    "  redpxs.append((r, 0, 0))\n",
    "\n",
    "himg = make_image(redpxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating color channel\n",
    "\n",
    "The above cell removes green and blue color information from our image, but we still have 3-channel pixels.\n",
    "\n",
    "If we want look at the values of a particular channel separately, we can extract the values from a particular channel and create a grayscale image that represents the strength (brightness) of that channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "himg_pxs = get_pixels(himg)\n",
    "\n",
    "# build array with single values from channel we're separating\n",
    "redpxs = []\n",
    "for r,g,b in himg_pxs:\n",
    "  redpxs.append(r)\n",
    "\n",
    "himg = make_image(redpxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could've also done the above using a one-line list comprehension expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "redpxs = [(r, 0, 0) for r,g,b in get_pixels(himg)]\n",
    "\n",
    "himg = make_image(redpxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "redpxs = [r for r,g,b in get_pixels(himg)]\n",
    "\n",
    "himg = make_image(redpxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving\n",
    "\n",
    "If we create something we want to keep, we can save an image to a file by calling the `.save()` function of an `Image` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(himg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg.save(\"./data/redhog.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove greens\n",
    "\n",
    "Go through the original pixels and remove the green pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove green CHANNEL\n",
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "# this is as simple as putting a zero in the green channel for all pixels\n",
    "\n",
    "npxs = []\n",
    "for r,g,b in get_pixels(himg):\n",
    "  npxs.append((r, 0, b))\n",
    "\n",
    "nimg = make_image(npxs, himg.width)\n",
    "nimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: removes green PIXELS\n",
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "# here we have to come up with some filtering logic to detect green pixels\n",
    "# let's try pixelsthat have g values greater than r and b, and also have g values greater than 30\n",
    "\n",
    "npxs = []\n",
    "for r,g,b in get_pixels(himg):\n",
    "  if g > r and g > b and g > 30:\n",
    "    npxs.append((0, 0, 0))\n",
    "  else:\n",
    "    npxs.append((r, g, b))\n",
    "\n",
    "nimg = make_image(npxs, himg.width)\n",
    "nimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturate colors\n",
    "\n",
    "We can also saturate colors, by increasing the value of a chosen channel in every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "display(himg)\n",
    "\n",
    "satpxs = []\n",
    "for r,g,b in get_pixels(himg):\n",
    "  # if the green channel is greater than the red and blue channels\n",
    "  if (g - r) > 16 and (g - b) > 16:\n",
    "    # make the green value 2 times larger\n",
    "    satpxs.append((r, 2 * g, b))\n",
    "  # else, keep original pixel values\n",
    "  else:\n",
    "    satpxs.append((r, g, b))\n",
    "\n",
    "himg = make_image(satpxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exaggerate the yellows\n",
    "\n",
    "How can we exaggerate the yellow flowers instead ?\n",
    "\n",
    "We get yellow when the `red` and `green` values of our pixel are similar and much greater than the `blue` value.\n",
    "\n",
    "First thing we have to do is detect the yellow pixels, then exaggerate their `red` and `green` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: exaggerate the yellows\n",
    "# logic: red is similar to green and both are greater than blue\n",
    "\n",
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "# update pixels here\n",
    "npxs = []\n",
    "for r,g,b in get_pixels(himg):\n",
    "  # if the green channel is similar to the red channel and both are greater than blue\n",
    "  if abs(g - r) < 32 and (g - b) > 16:\n",
    "    npxs.append((2 * r, 2 * g, b))\n",
    "  else:\n",
    "    npxs.append((r, g, b))\n",
    "\n",
    "# then display\n",
    "himg = make_image(npxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB to grayscale\n",
    "\n",
    "We can also remove colors by making the pixel have a single value equal to the average of its original RGB values.\n",
    "\n",
    "$\\displaystyle average = \\frac{R + G + B}{3}$\n",
    "\n",
    "This is a good way to estimate the luminosity of each pixel: brighter pixels will be white and darker pixels will be black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "bwpxs = []\n",
    "for r,g,b in get_pixels(himg):\n",
    "  gval = (r + g + b) // 3\n",
    "  bwpxs.append(gval)\n",
    "\n",
    "himg = make_image(bwpxs, himg.size[0])\n",
    "display(himg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-homework exercise\n",
    "\n",
    "Let's say we want to replicate this effect from *Schindler's List* to highlight a specific color in an image.\n",
    "\n",
    "<img src=\"./imgs/red-coat-filter.jpg\" width=\"720px\">\n",
    "\n",
    "The logic could be something like: if pixel is red, keep it, otherwise turn into greyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the hedgehog image\n",
    "\n",
    "We might want to keep the yellow pixels, and turn everything else grey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: keep only yellow pixels, make everything else greyscale\n",
    "# We get yellow when the `red` and `green` values of our pixel are similar \n",
    "#   and much greater than the `blue` value.\n",
    "\n",
    "fimg = PImage.open(\"./data/hog.jpg\")\n",
    "pxs = get_pixels(fimg)\n",
    "\n",
    "fpxs = []\n",
    "# TODO: iterate over fimg pixels and append correct pixel values to fpxs\n",
    "for r,g,b in pxs:\n",
    "  if abs(r-g) < 50 and b < 20 and r > b*2 and g > 120:\n",
    "    fpxs.append((r,g,b))\n",
    "  else:\n",
    "    l = int((r+g+b)/3)\n",
    "    fpxs.append((l,l,l))\n",
    "\n",
    "fimg = make_image(fpxs, fimg.width)\n",
    "display(fimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_distance(c0, c1):\n",
    "  return ((c0[0] - c1[0])**2 + (c0[1] - c1[1])**2 + (c0[2] - c1[2])**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: keep only yellow pixels, make everything else greyscale\n",
    "# We get yellow when the `red` and `green` values of our pixel are similar \n",
    "#   and much greater than the `blue` value.\n",
    "\n",
    "fimg = PImage.open(\"./data/hog.jpg\")\n",
    "pxs = get_pixels(fimg)\n",
    "\n",
    "fpxs = []\n",
    "yellow = (255, 230, 0)\n",
    "# TODO: iterate over fimg pixels and append correct pixel values to fpxs\n",
    "for r,g,b in pxs:\n",
    "  if color_distance((r,g,b), yellow) < 100:\n",
    "    fpxs.append((r,g,b))\n",
    "  else:\n",
    "    l = int((r+g+b)/3)\n",
    "    fpxs.append((l,l,l))\n",
    "\n",
    "fimg = make_image(fpxs, fimg.width)\n",
    "display(fimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by Color\n",
    "\n",
    "Let's formalize what we mean by filtering and be a bit more precise with what we are trying to do.\n",
    "\n",
    "Let's say we're working on a vegetation detector and we want to be able to separate the pixels that represent plants and flowers from pixels that represent animals and other things.\n",
    "\n",
    "We can start by creating a filter to separate the green pixels from our original image.\n",
    "\n",
    "This is different than looking at the `green` color channel, or removing the `red` and `blue` channels, or exaggerating the green pixels.\n",
    "\n",
    "In order to filter pixels of a certain color we have to go through the pixels and measure how similar they are to the color we wish to separate.\n",
    "\n",
    "There are many ways to define \"similar\" when working with colors, but to keep it simple, let's define a `color_distance()` function that calculates the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between two colors:\n",
    "\n",
    "$\\displaystyle dist = \\sqrt{\\left(R_0 - R_1\\right)^2 + \\left(G_0 - G_1\\right)^2 + \\left(B_0 - B_1\\right)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_distance(c0, c1):\n",
    "  return ((c0[0] - c1[0])**2 + (c0[1] - c1[1])**2 + (c0[2] - c1[2])**2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing pixels\n",
    "\n",
    "Now that we have a function for measuring color similarity we can go through the pixels and remove the ones that are very different from the color we want to keep. We'll remove pixels by turning them black with RGB value (0, 0, 0).\n",
    "\n",
    "Since we're making some pretty significant changes to our image, let's keep a copy of the original. We can do this by just calling the `copy()` member function of an image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "keep_color = (20, 180, 20) # green\n",
    "keep_color = (242, 224, 19) # yellow\n",
    "thold = 120\n",
    "\n",
    "filtpxs = []\n",
    "for r,g,b in get_pixels(himg):\n",
    "  if color_distance((r, g, b), keep_color) < thold:\n",
    "    filtpxs.append((r, g, b))\n",
    "  else:\n",
    "    filtpxs.append((0, 0, 0))\n",
    "\n",
    "fimg = make_image(filtpxs, fimg.size[0])\n",
    "\n",
    "display(himg)\n",
    "display(fimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter other colors\n",
    "\n",
    "How can we filter the image to keep only the flowers? Or to keep only the hedgehog?\n",
    "\n",
    "It might help to define a `filter_color()` function here that takes an image and a color to keep as inputs, and returns another image with just the kept pixels and black pixels ... while keeping the original image intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_color(img, keep_color, thold=150):\n",
    "  # TODO: fill this in\n",
    "  filtpxs = []\n",
    "\n",
    "  for r,g,b in get_pixels(img):\n",
    "    if color_distance((r, g, b), keep_color) < thold:\n",
    "      filtpxs.append((r, g, b))\n",
    "    else:\n",
    "      filtpxs.append((0, 0, 0))\n",
    "\n",
    "  return make_image(filtpxs, img.size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "\n",
    "# TODO: use filter_color to filter image to keep only flowers or to keep only the hedgehog\n",
    "keep_color_green = (20, 150, 20) # green\n",
    "keep_color_yello = (242, 224, 19) # yellow\n",
    "keep_color_white = (200, 200, 200) # white\n",
    "\n",
    "display(filter_color(himg, keep_color_green, 100))\n",
    "display(filter_color(himg, keep_color_yello))\n",
    "display(filter_color(himg, keep_color_white))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting pixels by colors\n",
    "\n",
    "Now that we can separate pixels by color, we could use it to create an automatic deforestation sensor by separating and counting green pixels, and calculating the percentage of green areas on images.\n",
    "\n",
    "We could implement a separate function to count the number of non-black pixels in an image after it has been filtered, but since our `filter_color()` function above already goes through all of the pixels in an image and detects pixels of specific colors, we can just create a modified version of it that counts those pixels and returns the ratio relative to the total number of pixels, instead of returning a filtered image.\n",
    "\n",
    "We can call this new function `color_ratio()` and it will take and image, a color and a threshold as parameters, like the `filter_color()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create color_ratio() function\n",
    "\n",
    "def color_ratio(img, keep_color, thold=150):\n",
    "  # TODO: modify the content of the filter_color() function\n",
    "  pxs = get_pixels(img)\n",
    "  pxcnt = 0\n",
    "  for r,g,b in pxs:\n",
    "    if color_distance((r, g, b), keep_color) < thold:\n",
    "      pxcnt += 1\n",
    "  return pxcnt / len(pxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try it out on a couple of forest images inside the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimg = PImage.open(\"./data/forest-00.jpg\")\n",
    "display(fimg)\n",
    "\n",
    "ffimg = filter_color(fimg, (0,200,0), 180)\n",
    "display(ffimg)\n",
    "\n",
    "green_ratio = color_ratio(fimg, (0,200,0), 180)\n",
    "print(f\"green %: {round(100 * green_ratio, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out on some other images\n",
    "\n",
    "There are $6$ other aerial forest images in the `data/` directory. Run the green pixel count code on them and see if the results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: count green pixels in forest images\n",
    "\n",
    "# Doing a for loop here, no surprises\n",
    "for i in range(7):\n",
    "    path = f\"./data/forest-0{i}.jpg\"\n",
    "    fimg = PImage.open(path)\n",
    "    display(fimg)\n",
    "\n",
    "    # TODO: filter by color to get good RGB values\n",
    "    ffimg = filter_color(fimg, (0,200,0), 180)\n",
    "    display(ffimg)\n",
    "\n",
    "    # TODO: use RGB values to calculate color ratio\n",
    "    green_ratio = color_ratio(fimg, (0,200,0), 180)\n",
    "    print(f\"{path} -> green %: {round(100 * green_ratio, 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we start doing image analysis it's good to be able to extract different kinds of information from our images in case we want to categorize them, filter them further or retrieve them from large databases later.\n",
    "\n",
    "This is kind of equivalent to how we extracted amplitude and frequency features from audio files.\n",
    "\n",
    "### Dominant Channel\n",
    "\n",
    "One feature we can easily extract from our images is the average value of each of its channels along with the average luminosity value.\n",
    "\n",
    "This can be used to give us some idea about the dominant color or tones in an images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "himg = PImage.open(\"./data/hog.jpg\")\n",
    "himg_pxs = get_pixels(himg)\n",
    "\n",
    "# array with 4 0s\n",
    "hog_rgbl_sum = 4 * [0]\n",
    "\n",
    "for r,g,b in himg_pxs:\n",
    "  l = (r + g + b) // 3\n",
    "  hog_rgbl_sum[0] += r\n",
    "  hog_rgbl_sum[1] += g\n",
    "  hog_rgbl_sum[2] += b\n",
    "  hog_rgbl_sum[3] += l\n",
    "\n",
    "hog_rgbl_avg = [s // len(himg_pxs) for s in hog_rgbl_sum]\n",
    "\n",
    "print(\"average RGBL values\", hog_rgbl_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both the `green` and `red` channels have average values above the average luminosity value.\n",
    "\n",
    "This makes sense since the image has a lot of green pixels, and the `red` channel contributes to the yellow and white pixels.\n",
    "\n",
    "### Repeat for other image\n",
    "\n",
    "Get the average value for each channel of a different image.\n",
    "\n",
    "Maybe create a function...\n",
    "\n",
    "Does the result make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get average channel value for other image\n",
    "\n",
    "def get_channel_avgs(img):\n",
    "  # TODO: fill this in\n",
    "  pxs = get_pixels(img)\n",
    "\n",
    "  # array with 4 0s\n",
    "  rgbl_sum = 4 * [0]\n",
    "\n",
    "  for r,g,b in pxs:\n",
    "    l = (r + g + b) // 3\n",
    "    rgbl_sum[0] += r\n",
    "    rgbl_sum[1] += g\n",
    "    rgbl_sum[2] += b\n",
    "    rgbl_sum[3] += l\n",
    "\n",
    "  return [s // len(pxs) for s in rgbl_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run function on image and print channel average values\n",
    "\n",
    "print(\"average RGBL values\", get_channel_avgs(himg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run function on another image and print channel average values\n",
    "wimg = PImage.open(\"./data/whale.jpg\")\n",
    "display(wimg)\n",
    "\n",
    "print(\"average RGBL values\", get_channel_avgs(wimg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makes sense to me. Whale image is full of blues and no reds. B has the highest value and R is pretty much numerically nonexistent. It's also on the brighter side, so 80 is OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection\n",
    "\n",
    "We've looked at some techniques for getting color information from images, but images are more than just colors.\n",
    "\n",
    "We might be interested in also quantifying the shapes and textures present in our images.\n",
    "\n",
    "We can start by extracting the edges of shapes in our image. There are many ways of doing this, but the simplest way is to subtract our original image from a blurry version of it and threshold the result.\n",
    "\n",
    "Since we are not so concerned with color at this point we should work with grayscale images.\n",
    "\n",
    "Our overall algorithm will be something like:\n",
    "- open an image\n",
    "- make it black & white\n",
    "- blur it\n",
    "- subtract the blurry b&w pixels from the original b&w pixels\n",
    "- threshold the result\n",
    "\n",
    "Threshold means making slightly bright pixels really bright and all other pixels really dark.\n",
    "\n",
    "Let's do this in steps:\n",
    "\n",
    "#### Open an image and extract its pixels\n",
    "\n",
    "We can use the `PImage.open()` and the `get_pixels()` functions to open and extract pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement edge extraction algorithm\n",
    "# TODO: open an image and extract its pixels\n",
    "\n",
    "mimg = PImage.open(\"./data/whale.jpg\")\n",
    "mpxs = get_pixels(mimg)\n",
    "\n",
    "display(mimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blur the image using `blur()`\n",
    "\n",
    "And display it.\n",
    "\n",
    "The `blur()` function takes an image object as a parameter and an optional second parameter that specifies the amount of blurring. It returns another image object.\n",
    "\n",
    "Experiment with the parameter a little bit, but the default value is good for extracting edges.\n",
    "\n",
    "Let's also get the pixels for the blurred image and display it with `display()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement edge extraction algorithm\n",
    "# TODO: blur image with the blur() function\n",
    "\n",
    "bimg = blur(mimg, 2)\n",
    "bpxs = get_pixels(bimg)\n",
    "\n",
    "display(bimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the images grayscale\n",
    "\n",
    "We saw this a few cells back. We can average the `RGB` values to get a grey luminance value.\n",
    "\n",
    "Get grayscale versions of the original image and the blurry image\n",
    "\n",
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement edge extraction algorithm\n",
    "# TODO: make the image b&w\n",
    "\n",
    "# TODO: make pixels and blurry pixels b&w\n",
    "bwpxs = [(r+g+b)//3 for r,g,b in mpxs]\n",
    "bwbpxs = [(r+g+b)//3 for r,g,b in bpxs]\n",
    "\n",
    "bwimg = make_image(bwpxs, mimg.size[0])\n",
    "display(bwimg)\n",
    "\n",
    "bwbimg = make_image(bwbpxs, bimg.size[0])\n",
    "display(bwbimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtract the blurred pixels from the original pixel values\n",
    "\n",
    "The `zip()` function might help iterate through the pixel arrays from both images at the same time.\n",
    "\n",
    "Display the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement edge extraction algorithm\n",
    "# TODO: subtract blurry b&w image from original b&w image\n",
    "\n",
    "# TODO: subtract bwbpxs from bwpxs\n",
    "spxs = [max(p-bp, 0) for p,bp in zip(bwpxs, bwbpxs)]\n",
    "\n",
    "simg = make_image(spxs, bwimg.size[0])\n",
    "display(simg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold the resulting pixel values\n",
    "\n",
    "We'll go through the array and check each pixel:<br>\n",
    "if its luminance is greater than a threshold value, we'll make it $255$, otherwise we'll make it $0$.\n",
    "\n",
    "We can start with a threshold value of $16$ and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement edge extraction algorithm\n",
    "# TODO: threshold pixel values\n",
    "\n",
    "# TODO: threshold pixels\n",
    "tpxs = [255 if p > 16 else 0 for p in spxs]\n",
    "\n",
    "timg = make_image(tpxs, simg.size[0])\n",
    "display(timg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great !\n",
    "\n",
    "### Let's repeat it for a different image\n",
    "\n",
    "First, create a function that takes an image as a parameter and returns another image with edge information.\n",
    "\n",
    "We just have to wrap up the previous steps into a function. It will be shorter since we don't have to display all the images along the way. That was only while debugging the logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create edge extraction function\n",
    "\n",
    "def edge(img, rad=1, thold=16):\n",
    "  # TODO: fill this in\n",
    "  bimg = blur(img, rad)\n",
    "  bwpxs = [(r+g+b)//3 for r,g,b in get_pixels(img)]\n",
    "  bbwpxs = [(r+g+b)//3 for r,g,b in get_pixels(bimg)]\n",
    "\n",
    "  dpxs = [abs(p-bp) for p,bp in zip(bwpxs, bbwpxs)]\n",
    "  tpxs = [255 if p > thold else 0 for p in dpxs]\n",
    "\n",
    "  return make_image(tpxs, img.size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test function on a couple of images using different parameters\n",
    "\n",
    "for path in [\"./data/my-cat.jpg\", \"./data/hog.jpg\", \"./data/flowers.jpg\"]:\n",
    "    img = PImage.open(path)\n",
    "    print(path)\n",
    "    display(img)\n",
    "    display(edge(img, 1, 12))\n",
    "    display(edge(img, 2, 16))\n",
    "    display(edge(img, 3, 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count edges\n",
    "\n",
    "It helps to have a single value that we can use to compare edge information between images.\n",
    "\n",
    "Let's create a function that counts the number of white pixels in an edge-extraction image.\n",
    "\n",
    "We'll divide this number by the number of pixels in the image to get a rough idea of how _edgy_ any image is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_ratio(img, rad=1, thold=16):\n",
    "  eimg = edge(img, rad=rad, thold=thold)\n",
    "  eimg_pxs = get_pixels(eimg)\n",
    "  sum255 = sum([1 for L in eimg_pxs if L > 250])\n",
    "  npxs = len(eimg_pxs)\n",
    "  return sum255 / npxs\n",
    "\n",
    "mimg = PImage.open(\"./data/hog.jpg\")\n",
    "display(edge(mimg, 2))\n",
    "round(100*edge_ratio(mimg, 2), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count edges for different images\n",
    "\n",
    "Do the results make sense? Why did we divide the sum by the total number of pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run the edge_ratio() function on a few images and compare results.\n",
    "# TODO: do the results make sense ? (i.e. do images with more \"things\" have more edges ?)\n",
    "\n",
    "# Time for another for loop\n",
    "for path in [\"./data/my-cat.jpg\", \"./data/flowers.jpg\", \"./data/hog.jpg\", \"./data/whale.jpg\", \"./data/arara.jpg\"]:\n",
    "    try:\n",
    "        fimg = PImage.open(path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{path} not found\")\n",
    "        continue\n",
    "\n",
    "    display(fimg)\n",
    "    print(f\"{path} -> edge %: {round(100 * edge_ratio(fimg, 2, 16), 3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I would say the results make sense. The parrot image has little to no edges. The whale almost none. My cat is on the lower side, and the flower one has the most edges, obviously."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
